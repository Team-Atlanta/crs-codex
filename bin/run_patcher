#!/usr/bin/env python3
"""
atlantis-codex patcher module.

Thin launcher that delegates vulnerability fixing to a swappable AI agent.
The agent (selected via CRS_AGENT env var) handles: bug analysis, code editing,
building (via libCRS), testing (via libCRS), iteration, and final patch
submission (writing .diff to /patches/).

To add a new agent, create a module in agents/ implementing setup() and run().
"""

import importlib
import logging
import os
import shutil
import subprocess
import sys
import time
import urllib.request
import urllib.error
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(name)s] %(levelname)s %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger("patcher")

# --- Configuration (from oss-crs framework environment variables) ---

SNAPSHOT_IMAGE = os.environ.get("OSS_CRS_SNAPSHOT_IMAGE", "")
TARGET = os.environ.get("OSS_CRS_TARGET", "")
HARNESS = os.environ.get("OSS_CRS_TARGET_HARNESS", "")
LANGUAGE = os.environ.get("FUZZING_LANGUAGE", "c")
SANITIZER = os.environ.get("SANITIZER", "address")
LLM_API_URL = os.environ.get("OSS_CRS_LLM_API_URL", "")
LLM_API_KEY = os.environ.get("OSS_CRS_LLM_API_KEY", "")

BUILDER_URL = os.environ.get("OSS_CRS_BUILDER_URL", "")

# Agent selection
CRS_AGENT = os.environ.get("CRS_AGENT", "codex")

# Crash log truncation limit (keep the tail â€” ASAN summaries are at the end)
MAX_CRASH_LOG_CHARS = 16384

# Framework directories
FETCH_DIR = Path("/OSS_CRS_FETCH_DIR")
WORK_DIR = Path("/work")
PATCHES_DIR = Path("/patches")


# --- Common infrastructure ---


def _reset_source(source_dir: Path) -> None:
    """Reset source directory to HEAD, cleaning up stale lock files."""
    for lock_file in source_dir.glob(".git/**/*.lock"):
        logger.warning("Removing stale lock file: %s", lock_file)
        lock_file.unlink()

    subprocess.run(
        ["git", "reset", "--hard", "HEAD"],
        cwd=source_dir, capture_output=True, timeout=60,
    )
    subprocess.run(
        ["git", "clean", "-fd"],
        cwd=source_dir, capture_output=True, timeout=60,
    )


def setup_source() -> Path | None:
    """Download source code and locate the project source directory."""
    source_dir = WORK_DIR / "src"
    source_dir.mkdir(parents=True, exist_ok=True)

    result = subprocess.run(
        ["libCRS", "download-build-output", "src", str(source_dir)],
        capture_output=True, text=True,
    )
    if result.returncode != 0:
        logger.error("Failed to download source: %s", result.stderr)
        return None

    project_dir = source_dir / "repo"
    if not project_dir.exists():
        for d in source_dir.iterdir():
            if d.is_dir() and (d / ".git").exists():
                project_dir = d
                break

    if not project_dir.exists() or not (project_dir / ".git").exists():
        logger.error("No git repo found in %s", source_dir)
        return None

    return project_dir


def wait_for_builder(timeout: int = 300) -> bool:
    """Block until the builder sidecar is healthy (safety net for startup races)."""
    if not BUILDER_URL:
        logger.warning("OSS_CRS_BUILDER_URL not set, skipping health check")
        return True

    health_url = f"{BUILDER_URL}/health"
    logger.info("Waiting for builder sidecar at %s ...", health_url)
    start = time.monotonic()
    while time.monotonic() - start < timeout:
        try:
            with urllib.request.urlopen(health_url, timeout=5) as resp:
                if resp.status == 200:
                    logger.info("Builder sidecar is healthy")
                    return True
        except (urllib.error.URLError, OSError):
            pass
        time.sleep(5)

    logger.error("Builder sidecar not healthy after %ds", timeout)
    return False


def reproduce_crash(pov_path: Path) -> str:
    """Reproduce crash via builder sidecar using the base (unpatched) build."""
    if not HARNESS:
        return "No harness configured"

    response_dir = WORK_DIR / f"pov-{pov_path.stem}" / "reproduce"
    response_dir.mkdir(parents=True, exist_ok=True)

    pov_cmd = [
        "libCRS", "run-pov",
        str(pov_path), str(response_dir),
        "--harness", HARNESS,
        "--build-id", "base",
    ]

    try:
        result = subprocess.run(
            pov_cmd, capture_output=True, text=True, timeout=180,
        )
        logger.info("reproduce_crash run-pov exit code: %d", result.returncode)

        pov_stderr = response_dir / "pov_stderr.log"
        if pov_stderr.exists():
            log = pov_stderr.read_text()
            if len(log) > MAX_CRASH_LOG_CHARS:
                log = "[...truncated...]\n" + log[-MAX_CRASH_LOG_CHARS:]
            return log

        return result.stdout or result.stderr or "No crash output captured"
    except subprocess.TimeoutExpired:
        return "Crash reproduction timed out (180s)"
    except Exception as e:
        return f"Error reproducing crash: {e}"


def load_agent(agent_name: str):
    """Dynamically load an agent module from the agents package."""
    module_name = f"agents.{agent_name}"
    try:
        return importlib.import_module(module_name)
    except ImportError as e:
        logger.error("Failed to load agent '%s': %s", agent_name, e)
        sys.exit(1)


def process_povs(pov_paths: list[Path], source_dir: Path, agent) -> bool:
    """Process a batch of POV variants in a single agent session.

    All POVs are assumed to be variants of the same vulnerability.
    We reproduce all crashes, then hand the full set to the agent so it
    can produce a patch that fixes all of them.

    Returns True if a patch was produced.
    """
    povs = []
    for pov_path in pov_paths:
        logger.info("Reproducing crash for POV: %s", pov_path.name)
        crash_log = reproduce_crash(pov_path)
        logger.info("Crash log for %s:\n%s", pov_path.name, crash_log)
        povs.append((pov_path, crash_log))

    _reset_source(source_dir)

    agent_work_dir = WORK_DIR / "agent"
    agent_work_dir.mkdir(parents=True, exist_ok=True)

    agent.run(source_dir, povs, HARNESS, PATCHES_DIR, agent_work_dir,
              language=LANGUAGE, sanitizer=SANITIZER)

    _reset_source(source_dir)

    patches = list(PATCHES_DIR.glob("*.diff"))
    if patches:
        logger.info("Patch produced: %s", [p.name for p in patches])
        return True

    logger.warning("Agent did not produce a patch")
    return False


# --- Main loop ---


def main():
    logger.info(
        "Starting patcher: target=%s harness=%s agent=%s snapshot=%s",
        TARGET, HARNESS, CRS_AGENT, SNAPSHOT_IMAGE or "(none)",
    )

    if not SNAPSHOT_IMAGE:
        logger.error("OSS_CRS_SNAPSHOT_IMAGE is not set.")
        logger.error("Set 'incremental_build: true' in crs-compose.yaml.")
        sys.exit(1)

    # Register patch submission directory with libCRS.
    PATCHES_DIR.mkdir(parents=True, exist_ok=True)
    submit_log = WORK_DIR / "register-submit-dir.log"
    submit_log.parent.mkdir(parents=True, exist_ok=True)
    result = subprocess.run(
        ["libCRS", "register-submit-dir", "--log", str(submit_log),
         "patch", str(PATCHES_DIR)],
        stdin=subprocess.DEVNULL, stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
    )
    if result.returncode != 0:
        logger.error("register-submit-dir failed (rc=%d)", result.returncode)
        sys.exit(1)
    logger.info("Patch submission watcher started (log=%s)", submit_log)

    # Register Codex home (including logs) as shared dir for post-run analysis.
    codex_home = Path.home() / ".codex"
    if codex_home.exists() and not codex_home.is_symlink():
        shutil.rmtree(codex_home)
    codex_home.mkdir(parents=True, exist_ok=True)
    result = subprocess.run(
        ["libCRS", "register-shared-dir", str(codex_home), "codex-home"],
        capture_output=True, text=True,
    )
    if result.returncode != 0:
        logger.warning("Failed to register codex-home shared dir: %s", result.stderr)
        codex_home.mkdir(parents=True, exist_ok=True)
    else:
        logger.info("Codex home shared at %s", codex_home)

    source_dir = setup_source()
    if source_dir is None:
        logger.error("Failed to set up source directory")
        sys.exit(1)

    logger.info("Source directory: %s", source_dir)

    # Load and configure agent
    agent = load_agent(CRS_AGENT)
    agent.setup(source_dir, {
        "llm_api_url": LLM_API_URL,
        "llm_api_key": LLM_API_KEY,
        "codex_home": str(codex_home),
    })

    if not FETCH_DIR.exists():
        logger.error("FETCH_DIR %s does not exist. Is the volume mounted?", FETCH_DIR)
        sys.exit(1)

    # All POVs are present before container starts (FETCH_DIR is read-only).
    # Scan once, batch all variants into a single agent session.
    pov_files = sorted(f for f in FETCH_DIR.rglob("*") if f.is_file() and not f.name.startswith("."))

    if not pov_files:
        logger.warning("No POV files found in %s", FETCH_DIR)
        sys.exit(0)

    logger.info("Found %d POV(s): %s", len(pov_files), [p.name for p in pov_files])

    if not wait_for_builder():
        logger.error("Cannot proceed without builder sidecar")
        sys.exit(1)

    if process_povs(pov_files, source_dir, agent):
        # Wait for the submission daemon to flush (batch_time=10s) before exiting.
        logger.info("Patch submitted. Waiting for daemon to flush...")
        time.sleep(30)


if __name__ == "__main__":
    main()
